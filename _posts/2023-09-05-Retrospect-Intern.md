---
title:  "2022 여름 인턴 회고" 

categories:
  - Log
tags:
  - [retrospect]

toc: true
toc_sticky: true
 
date: 2022-09-05
last_modified_at: 2023-08-13
---

- 2022 여름 인턴 끝나고 작성한 회고글입니다.


![intern_brown_2022.png](/assets/img/intern_brown_2022.png)

길다면 길고 짧다면 짧은 LINE에서의 여름 인턴이 끝났다.

인턴을 하고 보니 왜 인턴 후기 글이나 전환 관련 글이 적은지 알았다. 개개인의 상황이 너무 특수한 경우가 많다. 그래서 본인이 특정되기도 하고 자신의 글이 그렇게 도움이 되지 않는 경우도 많다. 그리고 회사 규모가 크다 보니 보안 문제가 엄격한 편이라 어디까지 이야기를 해야할 지 참 애매하다.

자세한 회사 이야기는 직접 만나서 듣도록 하고 velog에는 이번 인턴을 하면서 느꼈던 점들을 보편적으로 담백하게 풀어보려고 한다.



# 기술적 성장
흔히 사람들이 대형 IT기업에서 인턴을 가장 하고 싶어하는 이유는 인턴 그 자체로 배우는 것이 많기 때문이다. 전환을 실패하더라도 프로젝트의 퀄리티가 매우 좋아서 바로 다른 회사에서 데려갈 정도니 말이다.

나 역시 프로젝트를 통해 정말 많은 기술적 성장을 이룰 수 있었다고 생각한다. 학회에서 혼자 공부하거나 친구들과 같이 프로젝트를 했던 수준에서 현업에 직접 적용하고 고도화를 시켜나가면서 스텝업을 했다고 느낀다.


## Airflow
그 중에서도 가장 내가 적극적으로 쓴 기술은 바로 "Airflow"라 할 수 있겠다. 배치 아키텍처를 설계해야 했기에 관리도 쉽고 기능도 다양한 Airflow를 선택했다. 

그런데 생각보다 Airflow가 자료가 별로 없다. 그니까 적용 사례는 많은데 각자의 상황에 맞게 커스텀해서 쓰다 보니 나한테 정말 필요한 기능이나 구축 과정에 대한 자료는 정말 적다.

정말 운이 좋게도 내가 인턴하기 몇 달 전에 나온 <Apache Airflow 기반의 데이터 파이프라인> 책을 구할 수 있었고 이 책을 정말 몇 번을 봤는지 모르겠다. 

그리고 Airflow는 공식문서가 꽤나 잘 나온 편이라 문제가 생길 때면 Docs를 정독하곤 했다.

Airflow는 배치 환경을 운영하는 Workflow Manager의 일종이기에 구축을 넘어서서 직접 운영해보며 다양한 상황에 테스트해봐야 했다. 보통 토이프로젝트를 하다보면 한 번 돌려보고 성공하고 말았는데, 한 달 가까이 Airflow를 가동하다보니 정말 별의 별(..) 문제를 다 만나게 되었고 이를 해결하는 과정이 정말 고통스러웠다. ㅎㅎ..

## Spark
처음에는 데이터의 사이즈가 작은 것 같아 pandas를 쓰려고 했다. 그런데 멘토님이 데이터의 크기가 작은 것이 미안하다면서 데이터의 크기를 10배(..)로 늘려주셔서 Spark를 쓰지 않을 수가 없었다.

Spark는 원래 써본 경험이 있어 비교적 코드를 짤 수 있었다. 하지만 튜닝하는 과정에서 거의 코드를 뜯어 고치는 과정을 두 세번 겪었고 코드리뷰를 통해 정말 많은 것을 배울 수 있었다. 특히 Spark는 코드 리뷰를 받을 기회 자체가 학부생 입장에서는 없었는데, 리뷰를 받은 내용은 이번 인턴 과정에서 제일 큰 수확이라고 할 수 있을 정도로 귀중한 것들이다.

특히 그 과정에서 느꼈던 점을 조금 정리해보자면,

### Spark의 핵심은 Architecture
스파크를 정말 제대로 쓰고 싶다면 아키텍처에 대한 이해가 필수적이라 생각한다. 스파크는 빅데이터 처리를 위해 컴퓨팅 자원을 최대한 활용하여 데이터를 처리하고자 나온 기술이다. 따라서 그 아키텍처를 정확하게 이해하고 이에 맞춰 core 수, memory, partition 등을 설정해야 그 성능을 100% 누릴 수 있다.

나 역시 Spark 관련 트러블슈팅 문제를 해결하는 데 있어 대부분의 해결법은 아키텍처적으로 접근한 것이다. 역시 기본은 늘 중요하다.


### 현업에서는 Scala를 사용하더라
혼자 공부할 때는 pyspark를 주로 사용했는데, 현업에서 spark를 사용할 때는 대부분 scala로 코드를 작성했다. 우리회사 뿐 아니라 옆 회사도 보니까 scala로 짜는 것 같다.

물론 pyspark의 장점도 있다. 코드를 작성하는 것이 쉽고 사람도 구하기 쉬워 처음에 빠르게 파이프라인을 구축할 때는 좋다고 한다. 그런데 아무래도 데이터의 크기가 엄청나게 커지고 성능 이슈가 슬슬 나올 시점 부터는 Scala가 좋은가 보다. (입사하자마자 Scala 공부를 해야겠다..!)


## Data Engineering
멘토님이 말씀해주시길, 배치 환경을 구성하는 데 있어 가장 신경써야 하는 부분이 바로 "멱등성"과 "정합성"이라고 하셨다. 그 중에서도 이번 프로젝트에서 가장 중요하게 여겼던 것은 바로 "멱등성". 배치가 돌아가다 오류가 발생할 수도 있고, 아니면 기존 데이터가 오류가 생겨 이에 맞춰 다시 처리해야하는 경우가 있다. 이 과정에서 기존 데이터를 해치지 않고 중복을 방지하며 데이터가 올바르게 처리될 수 있도록 해야 했다. 단순히 내가 편한 방식대로 하다가는 멱등성을 해치는 경우가 많아 각 단계마다 멱등성을 해치는 요인이 있는지 확인해보고 일일이 코드를 뜯어고쳤던 기억이 난다.



# 커뮤니케이션
우리 팀의 경우 매일 아침마다 30분씩 멘토님과 스크럼 시간을 가졌고, 매주 월요일에는 리드님에게 일주일 동안 진행 상황을 브리핑해야 했다. 매일 이렇게 아침마다 발표 아닌 발표를 하다보니 내 프로젝트 진행 상황과, 현재까지의 개발 내용을 정확하게 이야기하는 능력이 매우 필요했다.

## 솔직할 용기
채용 전환형 인턴이기에 어떻게 보면 지금까지의 프로젝트 진행 상황을 솔직하게 말하는데는 큰 용기가 필요했다. 그럼에도 불구하고 나는 애초에 인턴을 배우고자 들어왔다는 마인드 (+ 초반에는 전환 가능성이 매우 낮다고 생각하여 이상한데서 이상한데서 용기를 얻었다.) 라 지금 내가 어디 까지 시도해봤고, 어디서 문제가 발생했는지 나는 솔직하게 말씀드렸다.

하지만 그 과정에서 나는 내가 나름 얻은 해결책을 여러 개를 제시하고 나름대로 논리적인 근거를 마련해갔다. 이렇게 말씀드리면 멘토님이 나의 사고 흐름에서 오류가 있는 부분을 교정해주시기도 하고 더 나은 방법을 제시해주시곤 했다. 이 과정을 8주 가까이 반복하다 보니 실력이 정말 빠른 속도로 오르고 있다는 것이 체감이 될 정도였다. 중요한 것은 "태도"였던 것이다.

## 기록하기
평소에도 노션에 공부한 것을 기록하는 습관이 있던 터라 스크럼 시간에도 지금까지의 진행 상황을 정말 구구절절 나열해갔다. 자유롭게 위키를 활용하라길래 스크럼 시간에 사용할 자료부터 프로젝트 스펙까지 정말 상세하게 적었다. 어느 정도로 상세하게 적었냐면 데이터를 처리하는 과정의 Flow를 일일이 ERD로 그리고 조인 과정, 데이터 처리 과정을 표로 정리하고 전부 draw.io로 그렸다.

초장에 이렇게 시작한 나머지 이렇게 상세하게 적는 모습이 내 아이덴티티?가 되어버렸다. 나는 사내 위키 문서를 참고해서 조금 더 기술 스펙을 잘 작성해보려고 노력했고 이것저것 따라하며 최대한 프로젝트 내용에 대해서 잘 설명했다. 그 과정에서 프로젝트를 좀 더 잘 이해할 수 있었고, 문제가 발생했을 때 해결책을 좀 더 빨리 찾을 수 있지 않았나 싶다.




# '데이터 엔지니어'라는 포지션
Data Engineer는 Data Analytics와 Data Scientist의 어딘가에 위치하여 참 애매해다는 인상을 받기 쉽다. 게다가 규모가 작은 기업에서 Data Engineering 업무는 백엔드 개발자가 겸해서 하는 경우도 상당히 많다.

하지만 LINE 정도 되는 규모가 큰 기업에서는 Data Enigneer의 Role이 정말 확실하게 정해져 있었다. 많은 업무들이 있지만 공통 저은 배치던 실시간이던 데이터를 불러오고 처리해서 비즈니스 상에서 유의미하게 활용할 수 있도록 한다는 것이다. 특히 우리 팀은 직접적으로 비즈니스 로직에 개입하고 데이터를 설계할 수 있다는 점에서 정말 팀에 잘 배정 받았다는 생각을 했다. 단순히 파이프라인만 구축하고 쿼리만 작성했다면 재미 없었을 것 같다.

더 나아가 데이터 엔지니어는 그 특성 상 도메인이 중요할 수 밖에 없는 것 같다. 결국 데이터를 뜯어보고 비즈니스의 특성에 맞게 데이터 처리/저장 방식과 그 아키텍처가 결정이 되기에 어떤 도메인의 데이터를 다루는지가 매우 중요하다. 그런 면에 있어 광고 도메인은 데이터 엔지니어에게 정말 최적의 분야라는 생각이다. 데이터로 할 수 있는 정말 극한까지 다룬다는 느낌을 받았다.



# 결국엔..

프로젝트를 끝내고 일주일 뒤에 전환 합격 이메일을 받았다. 되돌아보면 정말 최단루트로 내가 원하는 기업에 입사했다. 정말 운이 좋게도 우리 팀과 fit이 맞아서 인턴십에 붙었고, 운이 좋게도 내가 하고 싶었던 업무를 받았고, 운이 좋게도 정말 좋은 팀에서 케어를 받으며 개발을 할 수 있었다.

인턴십 후기를 더 구체적으로 쓰고 싶어도 그럴 수가 없다. 보안 상의 문제도 있지만, 개개인의 상황이 너무나도 특수하기 때문인 것 같다. 다른 누군가는 나와 다른 업무를 배정받고 본인이 뜻하지 않은 방향으로 프로젝트가 흘러갔을 수도 있고, 멘토님이 인턴에게 이렇게 지원을 열심히 해주시지 않을 수도 있다.

이렇게 모든 것들이 나의 노력과 더불어 "운"의 요소도 늘 함께하고 있다는 사실에 늘 겸손하게 살아야겠다고 생각을 한다. 그리고 이런 좋은 결실을 맺도록 도와준 내 주변 사람들에게 감사의 인사를 전하고 싶다.

![intern_certificate_2022.png](/assets/img/intern_certificate_2022.png)
